{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Models\n",
    "\n",
    "## Intro\n",
    "\n",
    "## A preliminary introduction to Markov Chains\n",
    "\n",
    "**A Markov Chain or Markov Model** is sequence of observations (or states) {$X_{1},...,X_{T}$} assuming that $X_{t}$ captures all the relevant information for predicting the future $(X_{t+1},...X_{T})$\n",
    "Said differently, $\\forall$ time t $\\in$ {$1,...,T$}, observation $X_{t}$  depends only on the previous observation, $X_{t-1}$. This is known as the **Markov Property**.\n",
    "* $X_1$ is called the initial state\n",
    "* $X_T$ is called the terminal state\n",
    "> NB: The space ${1,..,T}$ refers usually at a sequence of time steps, but it can also refer more generally to locations within a sequence (sequence of words, sequence of DNA, etc...)\n",
    "\n",
    "### Joint distribution\n",
    "If we assume discrete time steps, the joint distribution of a Markov Chain can be computed as follow:\n",
    "$p(X_{1:T})=P(X_1)p(X_2|X_1)p(X_3|X_2)...=p(X_1)\\prod_{t=2}^{T} p(X_t|X_{t-1})$\n",
    "\n",
    "* $p(X_{t}|X_{t-1})$ is called the transition function\n",
    "* if we assume that the transition function is independent of time, then the chain is defined as **homogeneous, stationary, or time-invariant**.\n",
    "\n",
    "### Transition Matrix of a stationary discrete Markov Chain:\n",
    "If the sequence of observations $X_{1},...,X_{T}$ are discrete, the transition function $p(X_{t}|X_{t-1})$ can be written as a $K*K$ matrix, defined as the **transition matrix A**:\n",
    "$A=[A_{i,j}, (i,j) \\in K*K]=p(X_{t}=j|X_{t-1}=i)$\n",
    "* $\\sum_{j} A_{ij}=1$: A is a stochastic matrix.\n",
    "\n",
    "![example of a Markov Chain Transition Diagram](/Users/alicemartin/03_DOCUMENTATION/06_C_Reinforcement-Learning/Hidden-Markov-Models/HMMs-screenshots-from-ML-a-probabilistic-perspective/MC_transitionDiagram.png)\n",
    "\n",
    "> One major application of Markov Models is language modelling: languages models compute probability distributions over sequence of words. Language models can be used for: **sentence completion** (predicting the next given the previous words in a sentence), **data compression** (assigning short codewords to more probable strings), **text classification** (any density model can be used as a class-conditional density and hence turned into a generative classifier), **automatic essay writing** (we can sample from $p(x_{1:t}$) to generate artificial text)\n",
    "\n",
    "### Stationary distribution of a Markov Chain\n",
    "A Markov Chain can also be interpreted as stochastic dynamical systems: in that case, we are often interested in the long-term distribution over states, called the **stationary distribution** of the chain.\n",
    "**Stationary distribution definition**:\n",
    "* Let $\\pi_t(j)=p(X_t=j)$ the probability of being in state j at time t.\n",
    "* $\\pi_t(j)=\\sum_{i} \\pi_0(i)A_{ij}$ or in matrix notation $\\pi_t=\\pi_{t_1}A$\n",
    "* If we reach a stage where, $\\pi=\\pi*A$, we say that we have reached **the stationary distribution**: once we enter the stationary distribution, we will never leave.\n",
    "\n",
    "> **When does a stationary distribution exist?**:\n",
    "> Every irreducible$^*$ aperiodic$^{**}$ finite state Markov chain has a unique stationary distribution.\n",
    "> $^*$ _irreducible_ means that the state transition diagram is a single connected component, i.e we can get from any state to any other state.\n",
    "> **  a chain is _aperiodic_ if all the states are aperiodic, i.e for all i $\\in {1,..,T}$, $d(i)=$greatest common divisor {$t: A_{ii}(t) > 0$}$=1$\n",
    "\n",
    "## Hidden Markov Models: Definition, Theory, Concepts\n",
    "\n",
    "### 1. Definition:\n",
    "A **Hidden Markov Model or HMM** is a discrete-time, discrete-state Markov Chain, with hidden states $z_t \\in {1,...,K}$, plus a sequence of observations {x_1,...,X_T} defined by _**an observation model**_ $p(x_t|z_t)$ giving the probability of observing at time _t_ the observation $x_t$ knowing $z_t$.\n",
    "* {$z_1,...,z_T$} are called the hidden states because they are usually not directly observable. They are the variables we would like to estimate/predict.\n",
    "* The sequence of observations {$x_1,...x_T$} are by definition observable. But note that they are not necessary following the Markov property.\n",
    "\n",
    "### 2. Joint distribution of a HMM:\n",
    "$p(z_{1:T},x_{1:T})=p(Z_{1:T})p(X_{1:T}|z_{1:T})=[p(z_1)\\prod_{t=2}^{T} p(z_t|z-{t-1}]*[\\prod_{t=1}^T p(x_t|z_t)]$\n",
    "\n",
    "*The first term of the equation represent the **transition probabilities** (probability between two consecutive hidden states), while the second term represent the **emission probabilities** (conditional probability of observing the observation at time t knowing the hidden state).*\n",
    "* The observations in an HMM can be discrete or continuous.\n",
    "* If they are discrete, the observation model is an observation matrix B: $p(x_t=l|z_t=k,\\theta)=B(k,l)$\n",
    "* If they are continuous, it is common to be a conditional Gaussian: $p(x_t=l|z_t=k,\\theta)$=$N(x_t|\\mu_k,\\sum_k)$\n",
    "\n",
    "### 3. Applications of HMMs\n",
    "HMMs can be used as **black-box density models on sequences**. They have the advantage over the Markov models in that they can represent long-range dependencies between observations, mediated via the latent variables.\n",
    "One major application of HMMs is time-series predictions.\n",
    "It is common to give some meaning to the hidden states, and then try to estimate the hidden states from the observations, i.e to compute the term **$p(z_t|x_{1:t})$** (online scenario) or **$p(z_t|x_{1:T})$** (offline scenario).\n",
    "> **Some classic examples of HMMs applications:**\n",
    "> * **Automatic Speech recognition**: $x_t$ represents the features extracted from the speech signal, $z_t$ represents the work being spoken.\n",
    "> * **Activity Recognition**: $x_t$ represents features extracted from the a video frame, $z_t$ is the class of activity the person is engaged in (running, walking...)\n",
    ">* **Gene finding**: $x_t$ represents the DNA nucleotides and $z_t$ represents where if we are in a gene-coding region or not.\n",
    ">* **Medical Diagnosis**: $x_t$ represents the medical observations of a patient and $z_t$ represents the medical diagnosis.\n",
    "\n",
    "### 4. Inference in HMMs: type of inference problems and inference algorithms\n",
    "\n",
    "#### A. Type of inference problems for temporal models\n",
    "* **Filtering** means to compute the **belief state $p(z_t|x_{1:t}$)** online or recursively as the data streams in.\n",
    "* **Smoothing** means to compute **$p(z_t|x_{1:T})$** offline given all the evidence.\n",
    "* **Fixed lag smoothing** computes **$p(z_{t-l}|x_{1:t})$** where l>0 is called the lag (better performance than filtering but introduces a slight delay).\n",
    "* **Prediction**: predicting the future given the past, i.e, to compute **$p(z_{t+h}|x_{1:t})$** where h>0 is the prediction horizon.\n",
    ">NB: $p(z_{t+h}|x_{1:t})$ is a prediction about future hidden states. It can be easily converted about a prediction of future observations using the formula: $p(x_{t+h}|x_{1:t})=\\sum_{z_{t+h}} p(x_{t+h}|z_{t+h})p(z_t+h|x_{1:t})$\n",
    "* **MAP estimation** computes **$argmax_{z_{1:T}}p(z_{1:T}|x_{1:T})$**, the most probable state sequence. Known as _Viterbi decoding_ in the context of HMMs.\n",
    "\n",
    "![Illustration of HMM inference problems](/Users/alicemartin/03_DOCUMENTATION/06_C_Reinforcement-Learning/Hidden-Markov-Models/HMMs-screenshots-from-ML-a-probabilistic-perspective/HMM_inferenceModels.png)\n",
    "\n",
    "#### B. The forward algorithm:\n",
    "![The forward algorithm](/Users/alicemartin/03_DOCUMENTATION/06_C_Reinforcement-Learning/Hidden-Markov-Models/HMMs-screenshot-from-slides/The-forward-alg.png)\n",
    "\n",
    "#### C. The forward-backward algorithm:\n",
    "![The backward algorithm](/Users/alicemartin/03_DOCUMENTATION/06_C_Reinforcement-Learning/Hidden-Markov-Models/HMMs-screenshot-from-slides/backward-alg.png)\n",
    "\n",
    "\n",
    "![The forward-backward algorithm](/Users/alicemartin/03_DOCUMENTATION/06_C_Reinforcement-Learning/Hidden-Markov-Models/HMMs-screenshot-from-slides/forward-backwzrd-alg.png)\n",
    "\n",
    "\n",
    "#### D. The Viterbi algorithm\n",
    "![Viterbi algorithm](/Users/alicemartin/03_DOCUMENTATION/06_C_Reinforcement-Learning/Hidden-Markov-Models/HMMs-screenshot-from-slides/Vitterbi-alg.png)\n",
    "\n",
    "### 5. Learning with HMMs: example of training with fully observable data.\n",
    "We now discuss how to estimate the parameter **$\\theta=(\\pi,A,B)$** where, as defined previously:\n",
    "*  $\\pi(i)=p(z_1=i)$ is the initial state distribution.\n",
    "* $A(i,j)=p(z_{t}=j|p(z_{t-1}=i)$ is the transition matrix\n",
    "* $B_{j_{j \\in K}}(j)=p(x_t|z_t=j)$\n",
    "There are 2 cases: $z_{1:T}$ is observed in the training set, or $z_{1:T}$ is hidden: we will focus on the simpler fully observable case.\n",
    "\n",
    "#### Maximum Likehood Estimation (MLE) for A and $\\pi$\n",
    "\n",
    "#### MLE of B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
